{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa82ce10",
   "metadata": {},
   "source": [
    "## C-Trap Unzippong Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f125c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "import lumicks.pylake as lk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import IPython.display as ipy\n",
    "import warnings\n",
    "import math\n",
    "import seaborn\n",
    "import statistics\n",
    "import re\n",
    "import psutil\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953541d2",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a014182",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checks for a baseline mapping file and baseline file corresponding to the specified curve\n",
    "def has_baseline(folder, curve):\n",
    "    folder += '/baseline/'\n",
    "    base = 'baselines.csv'\n",
    "    \n",
    "    #check for baseline folder\n",
    "    if not os.path.exists(folder):\n",
    "        return -1\n",
    "    \n",
    "    #find baseline mapping file\n",
    "    for filename in os.listdir(folder):\n",
    "        if os.path.isfile(folder+base) and base in filename:\n",
    "            baselines = pd.read_csv(folder+filename)\n",
    "            break\n",
    "    \n",
    "    #find corresponding baseline for the curve\n",
    "    for col in baselines.columns:\n",
    "        if int(curve) in baselines[col].values or float(curve) in baselines[col].values:\n",
    "            return int(col)\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From a filename, data (force, trap positions, and time) are extracted from Lumicks H5 files and downsampled to\n",
    "#a desired frequncy. Addresses some bugs in data export that arose in different versions of Lumicks BlueLake software\n",
    "def h5_extract(f, compress = 78125, shift = 0):\n",
    "    \n",
    "    #import file\n",
    "    file = lk.File(f)\n",
    "    \n",
    "    try:\n",
    "    #extract high frequency force and time (F, t)\n",
    "        F2x = file[\"Force HF\"][\"Force 2x\"]\n",
    "        F2y = file[\"Force HF\"][\"Force 2y\"]\n",
    "        F2 = F2x.data\n",
    "        F1x = file[\"Force HF\"][\"Force 1x\"]\n",
    "        F1y = file[\"Force HF\"][\"Force 1y\"]\n",
    "        F1 = F1x.data\n",
    "        t = F2x.seconds\n",
    "    except:\n",
    "        print('Issue with forces, not downsampled')\n",
    "        return np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0)\n",
    "    \n",
    "    #LUMICKS BUG: STARTING AUGUST 2023 position1x data was stored in position1Y and vice versa \n",
    "    try:\n",
    "        #extract high frequency trap position (p)\n",
    "        #position1x = file[\"Trap position\"]['1X']\n",
    "        position1x = file[\"Trap position\"]['1Y']\n",
    "        p1x = position1x.data\n",
    "        position2x = file[\"Trap position\"]['2Y']\n",
    "        p2x = position2x.data\n",
    "        position1y = file[\"Trap position\"]['1X']\n",
    "        p1y = position1y.data\n",
    "        position2y = file[\"Trap position\"]['2X']\n",
    "        p2y = position2y.data\n",
    "        #position2x = file[\"Trap position\"]['2X']\n",
    "    except:\n",
    "        print('Issue with trap positions, not downsampled')\n",
    "        return np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0), np.empty(0)\n",
    "    \n",
    "    #down sample high frequency data to usable frequency\n",
    "    #at some point Lumicks began exporting position2x and position2y as a single 0, not an array\n",
    "    #0 array created in a later function\n",
    "    compressedF2y = F2y.downsampled_to(compress, method=\"force\")\n",
    "    compressedF1y = F1y.downsampled_to(compress, method=\"force\")\n",
    "    compressedF1x = F1x.downsampled_to(compress, method=\"force\")\n",
    "    compressedF2x = F2x.downsampled_to(compress, method=\"force\")\n",
    "    compressedP1x = position1x.downsampled_to(compress, method=\"force\")\n",
    "    compressedP1y = position1y.downsampled_to(compress, method=\"force\")\n",
    "    #compressedP2x = position2x.downsampled_to(compress, method=\"force\")\n",
    "    #compressedP2y = position2y.downsampled_to(compress, method=\"force\")\n",
    "\n",
    "    cP1x = compressedP1x.data\n",
    "    cP1y = compressedP1y.data\n",
    "    mF1x = compressedF1x.data*-1\n",
    "    mF2x = compressedF2x.data\n",
    "    mt = compressedF1x.seconds\n",
    "\n",
    "    mF2y = compressedF2y.data\n",
    "    mF1y = compressedF1y.data*-1\n",
    "    \n",
    "    print('compressed from ' + str(t.size) + ' to ' + str(mt.size))\n",
    "    \n",
    "    return mt, mF1x, mF1y, cP1x, mF2x, mF2y, cP1y, p2x, p2y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#return array of indeces for baseline subtraction. Finds index of closest baseline trap position to data trap position\n",
    "#adapted from: https://stackoverflow.com/questions/2566412/find-nearest-value-in-numpy-array\n",
    "def find_nearest(array1, array2):\n",
    "    array1 = np.asarray(array1)\n",
    "    array2 = np.asarray(array2)\n",
    "    idx = []\n",
    "    for v in array1:\n",
    "        idx.append(np.abs(array2 - v).argmin())\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724c9252",
   "metadata": {},
   "outputs": [],
   "source": [
    "#given which variable to search, uses sliding window to find a specified number of peaks/valleys or\n",
    "#prompt the user (if peaks == -1) for a number of peaks/valleys. Can be used to find cycle starts and stops and/or force peaks\n",
    "#'trap' is default and finds cycles, 'f' finds force peaks\n",
    "def find_peaks(df, date, curve, cycle, grna = -1, var = 'trap', sign = '+', num_peaks = -1, interval = 1000, peak_dict=None):#, peak_types=[]):\n",
    "    \n",
    "    #initialize variables\n",
    "    possiblex = []\n",
    "    possibley = []\n",
    "    num_in = -1\n",
    "    start = 0\n",
    "    label = 'peak'\n",
    "    if sign == '-':\n",
    "        label = 'valley'\n",
    "\n",
    "    #confirm variable types are valid\n",
    "    while var != 'trap' and var != 'f':\n",
    "        print('Bad entry for \"var\", enter \"trap\" or \"f\"')\n",
    "        var = input()\n",
    "        \n",
    "    while sign != '+' and sign != '-':\n",
    "        print('Bad entry for \"sign\", enter \"+\" or \"-\" for peaks or valleys, respectively')\n",
    "        var = input()\n",
    "\n",
    "    #if number of peaks not specified, plot and ask. If called or answered with 0, exit\n",
    "    if num_peaks == -1:\n",
    "        fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize = (15, 5))\n",
    "        ax1.plot(df['trap_position 1x'], df['force baseline 2x'])\n",
    "        ax2.plot(df['time (seconds)'], df['force baseline 2x'])\n",
    "        ax3.plot(df['time (seconds)'], df['trap_position 1x'])\n",
    "        ax1.set(xlabel = 'Extension (um)', ylabel = 'Force (pN)', title = 'Curve ' + str(curve))\n",
    "        ax2.set(xlabel = 'Time (seconds)', ylabel = 'Force (pN)', title = 'Curve ' + str(curve))\n",
    "        ax3.set(xlabel = 'Time (seconds)', ylabel = 'Trap position (um)', title = 'Curve ' + str(curve))\n",
    "        plt.show()\n",
    "        if var == 'trap':\n",
    "            print('How many cycles? (out and back is 1, just out is 0.5)')\n",
    "        elif var == 'f':\n",
    "            print('How many force rips?')\n",
    "        num_in = input()\n",
    "        num_peaks = num_in\n",
    "        ipy.clear_output()\n",
    "    else:\n",
    "        num_in = num_peaks\n",
    "    \n",
    "    #exit function if no peaks to be found\n",
    "    if num_peaks == '0' or num_peaks == 0:\n",
    "        return [], [], 0, peak_dict\n",
    "    \n",
    "    #adjust number of peaks if non-integer value (for example,0.5 means only forward, no reverse)\n",
    "    if sign == '-' and var == 'trap':\n",
    "        num_peaks = math.floor(float(num_peaks)) + 1\n",
    "        search_max = 2\n",
    "    elif sign == '+' and var == 'trap':\n",
    "        num_peaks = math.ceil(float(num_peaks))\n",
    "        search_max = 2\n",
    "    elif var == 'f':\n",
    "        num_peaks = int(num_peaks)\n",
    "        search_max = 1.5\n",
    "    \n",
    "    #loop through until user satisfied\n",
    "    answer = 0\n",
    "    while answer == 0:\n",
    "        \n",
    "        #initialize varibales\n",
    "        possiblex = []\n",
    "        possibley = []\n",
    "        start = 0\n",
    "        \n",
    "        #search along the curve in every window and find the max or min in the window (trap position or force)\n",
    "        while start < len(df.index)-1:\n",
    "            stop = start + interval\n",
    "            stop = min(stop, len(df.index)-1)\n",
    "            df2 = df.iloc[start:stop, :]\n",
    "\n",
    "            #to split into cycles, find local maxima and minima for trap position\n",
    "            if var == 'trap':\n",
    "                if sign == '+':\n",
    "                    possibley.append(max(df2['trap_position 1x']))\n",
    "                    possiblex.append(df2['trap_position 1x'].idxmax())\n",
    "                elif sign == '-':\n",
    "                    possibley.append(min(df2['trap_position 1x']))\n",
    "                    possiblex.append(df2['trap_position 1x'].idxmin())\n",
    "            \n",
    "            #to find force peaks, find local maxima\n",
    "            elif var == 'f':\n",
    "                if sign == '+':\n",
    "                    if df['trap_position 1x'].iloc[df2['force baseline 2x'].idxmax()] < search_max:\n",
    "                        possibley.append(max(df2['force baseline 2x']))\n",
    "                        possiblex.append(df2['force baseline 2x'].idxmax())\n",
    "                elif sign == '-':\n",
    "                    possibley.append(min(df2['force baseline 2x']))\n",
    "                    possiblex.append(df2['force baseline 2x'].idxmin())\n",
    "            start += interval\n",
    "\n",
    "        #order the list of possible peaks, remove duplicates, and select highest\n",
    "        rev = True\n",
    "        if sign == '-':\n",
    "            rev = False\n",
    "        \n",
    "        #makes sure peaks are at least 5 seconds appart\n",
    "        if var == 'trap':\n",
    "            l = len(possiblex)\n",
    "            for i in range(0, l-1):\n",
    "                check = l-i-1\n",
    "                #print(check)\n",
    "                if abs(df['time (seconds)'].iloc[possiblex[check]] - df['time (seconds)'].iloc[possiblex[check-1]]) < 2:\n",
    "                    if (sign == '-' and possibley[check] > possibley[check-1]) or (sign == '+' and possibley[check] < possibley[check-1]):\n",
    "                        del possiblex[check]\n",
    "                        del possibley[check]\n",
    "                    else:\n",
    "                        del possiblex[check-1]\n",
    "                        del possibley[check-1]\n",
    "        \n",
    "        #Too debug issue where first cycle minima missed\n",
    "        if sign == '-' and len(possiblex) < num_peaks:\n",
    "            possibley.append(df2.iloc[0]['force baseline 2x'])\n",
    "            possiblex.append(0)\n",
    "        \n",
    "        possibley, possiblex = zip(*sorted(zip(possibley, possiblex), reverse=rev))\n",
    "        \n",
    "        #pick top (or bottom) peaks\n",
    "        peaksx = possiblex[0:num_peaks]\n",
    "        peaksy = possibley[0:num_peaks]\n",
    "        \n",
    "        peaksx, peaksy = zip(*sorted(zip(peaksx, peaksy)))\n",
    "\n",
    "        #have user validate the peaks and save if correct\n",
    "        #ipy.clear_output()\n",
    "        fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize = (15, 5))\n",
    "        ax1.plot(df['trap_position 1x'], df['force baseline 2x'])\n",
    "        ax2.plot(df['time (seconds)'], df['force baseline 2x'])\n",
    "        ax3.plot(df['time (seconds)'], df['trap_position 1x'])\n",
    "        ax1.set(xlabel = 'Extension (um)', ylabel = 'Force (pN)', title = date + ' Curve ' + str(curve) + ' Cycle ' + str(cycle))\n",
    "        ax2.set(xlabel = 'Time (seconds)', ylabel = 'Force (pN)', title = date + ' Curve ' + str(curve) + ' Cycle ' + str(cycle))\n",
    "        ax3.set(xlabel = 'Time (seconds)', ylabel = 'Trap position (um)', title = 'Curve ' + str(curve))\n",
    "        for i in range(0, len(peaksy)):\n",
    "            if var == 'f':\n",
    "                f = df['force baseline 2x'].iloc[peaksx[i]]\n",
    "                p = df['trap_position 1x'].iloc[peaksx[i]]\n",
    "                d = df['trap_position 1x'].iloc[peaksx[i]]\n",
    "                ax1.axhline(y=f, color='r')\n",
    "                ax1.axvline(x=d, color='r')\n",
    "                ax2.axhline(y=f, color='r')\n",
    "                ax3.axhline(y=p, color='r')\n",
    "                print(label + ' ' + str(i+1) + ' is at ' + str(f) + ' pN, ' + str(d) + ' um extension, ' + str(p) + ' trap position')\n",
    "            if var == 'trap':\n",
    "                d = df['trap_position 1x'].iloc[peaksx[i]]\n",
    "                t = df['time (seconds)'].iloc[peaksx[i]]\n",
    "                p = df['trap_position 1x'].iloc[peaksx[i]]\n",
    "                ax1.axvline(x=d, color='r')\n",
    "                ax2.axvline(x=t, color='r')\n",
    "                ax3.axvline(x=t, color='r')\n",
    "                print(label + ' ' + str(i+1) + ' is at ' + str(d) + ' um extension, ' + str(t) + \" seconds, and \" + str(p) + ' trap position')\n",
    "        plt.show()\n",
    "        print('Do ' + label + 's look correct? yes = 1, no = 0')\n",
    "        answer = int(input())\n",
    "        if answer == 0 and var == 'trap':\n",
    "            print('new window size? was ' + str(interval))\n",
    "            interval = int(input())\n",
    "            ipy.clear_output()\n",
    "        elif answer == 0 and var == 'f':\n",
    "            print('New maximum distance to search? Was ' + str(search_max) + ' um')\n",
    "            search_max = float(input())\n",
    "            print('new window size? was ' + str(interval))\n",
    "            interval = int(input())\n",
    "            ipy.clear_output()\n",
    "        elif answer ==1 and var == 'f' and peak_dict != None:\n",
    "            for i in range(0, len(peaksy)):\n",
    "                \n",
    "                peak_dict['Date'].append(date)\n",
    "                peak_dict['Curve'].append(curve)\n",
    "                peak_dict['Cycle'].append(cycle)\n",
    "                peak_dict['Force'].append(peaksy[i])\n",
    "                peak_dict['Index'].append(peaksx[i])\n",
    "                peak_dict['Trap Position'].append(df['trap_position 1x'].iloc[peaksx[i]])\n",
    "                peak_dict['Distance'].append(df['trap_position 1x'].iloc[peaksx[i]])\n",
    "                peak_dict['Time'].append(df['time (seconds)'].iloc[peaksx[i]])\n",
    "                peak_dict['gRNA'].append(grna)\n",
    "                \n",
    "                print('What Cas9 site is peak ' + str(i+1) + ' at? (0 = WT, 1 = MM, 2 = Off)')\n",
    "                peakt = int(input())\n",
    "                if peakt == 1:\n",
    "                    print('How many mismatches?')\n",
    "                    peak_dict['Mismatches'].append(int(input()))\n",
    "                    peak_dict['Mismatch Site'].append(1)\n",
    "                    peak_dict['WT Site'].append(0)\n",
    "                    peak_dict['Off Site'].append(0)\n",
    "                    print('Did peak slide or is sliding? (0 = no, 1 = yes)')\n",
    "                    peak_dict['Slid'].append(int(input()))\n",
    "                else:\n",
    "                    peak_dict['Mismatch Site'].append(0)\n",
    "                    peak_dict['Mismatches'].append(-1)\n",
    "                    peak_dict['Slid'].append(0)\n",
    "                    \n",
    "                if peakt == 0:\n",
    "                    peak_dict['WT Site'].append(1)\n",
    "                    peak_dict['Off Site'].append(0)\n",
    "                elif peakt == 2:\n",
    "                    peak_dict['WT Site'].append(0)\n",
    "                    peak_dict['Off Site'].append(1)\n",
    "                    \n",
    "\n",
    "    ipy.clear_output()\n",
    "    return peaksx, peaksy, num_in, peak_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4abf707",
   "metadata": {},
   "outputs": [],
   "source": [
    "#functions that imports all csv files in a specified directory and returns a list of filenames \n",
    "\n",
    "def select_files(date, file_type, directory, selections = [], cycles = False):\n",
    "    \n",
    "    #initialize variables needed for selection\n",
    "    folder = directory + date\n",
    "    types = ['h5', 'down', 'calibration']\n",
    "    if file_type in types:\n",
    "        types.remove(file_type)\n",
    "    out_parts = types\n",
    "    file_list=[]\n",
    "    if cycles:\n",
    "        folder += '/cycles'\n",
    "\n",
    "    #loop through specified folder and append all desired files to list\n",
    "    for filename in os.listdir(folder):\n",
    "        fi = os.path.join(folder, filename)\n",
    "        \n",
    "        #by default include; if no type provided, include all\n",
    "        check = True\n",
    "        if file_type == '':\n",
    "            if os.path.isfile(fi) and check:\n",
    "                file_list = np.append(file_list, fi)\n",
    "                continue\n",
    "\n",
    "        #make sure the correct file type\n",
    "        if file_type not in fi:\n",
    "            continue\n",
    "        for part in out_parts:\n",
    "            if part in fi:\n",
    "                check = False\n",
    "        if check == False:\n",
    "            continue\n",
    "                \n",
    "        #if list of curves specified, make sure it's a desired one\n",
    "        #if there's a list, make sure it's in it\n",
    "        if selections:\n",
    "            curve = int(extract_curve_number(fi))\n",
    "            if cycles:\n",
    "                cycle = int(extract_cycle_number(fi))\n",
    "            check = False\n",
    "            for s in selections:\n",
    "                if type(s) == tuple and s[0] == curve and s[1] == cycle:\n",
    "                    check = True\n",
    "                elif s == curve:\n",
    "                    check = True\n",
    "                \n",
    "        if os.path.isfile(fi) and check:\n",
    "            file_list = np.append(file_list, fi)\n",
    "\n",
    "    file_list = np.sort(file_list)\n",
    "    \n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1208c6d4-eb9a-475d-acce-042fbaa5db54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot a list of input files on top of eachother and return the resulting figure\n",
    "#accepts arguments for type of plots (d = force v extension, t = force v time, d/t = both side by side,\n",
    "#d/t/p = both side by side + position vs time)\n",
    "#and a title and legend\n",
    " \n",
    "def plot_curves(file_list, plot='d/t', ftitle = '', legend=True, font=16, color='', smooth=False, xlim=False):\n",
    "    \n",
    "    #initialize list of curves for legend\n",
    "    curves = []        \n",
    "    \n",
    "    #create specified figure type with labels\n",
    "    if plot == 'd/t':\n",
    "        fig, [ax1, ax2] = plt.subplots(1, 2, figsize = (15, 5))\n",
    "        ax1.set(xlabel = 'Extension (um)', ylabel = 'Force (pN)', title = ftitle)\n",
    "        ax2.set(xlabel = 'Time (seconds)', ylabel = 'Force (pN)', title = ftitle)\n",
    "    elif plot == 'd/t/p':\n",
    "        fig, [ax1, ax2, ax3] = plt.subplots(1, 3, figsize = (15, 5))\n",
    "        ax1.set(xlabel = 'Extension (um)', ylabel = 'Force (pN)', title = ftitle)\n",
    "        ax2.set(xlabel = 'Time (seconds)', ylabel = 'Force (pN)', title = ftitle)\n",
    "        ax3.set(xlabel = 'Time (seconds)', ylabel = 'Trap Position (um)', title = ftitle)\n",
    "    elif plot == 'd':\n",
    "        fig = plt.figure()\n",
    "        plt.xlabel('Extension (um)', fontsize=font)\n",
    "        plt.ylabel('Force (pN)', fontsize=font)\n",
    "        plt.title(ftitle, fontsize=font)\n",
    "    elif plot == 't':\n",
    "        fig = plt.figure(figsize=(12, 4))\n",
    "        plt.xlabel('Time (seconds)', fontsize=font)\n",
    "        plt.ylabel('Force (pN)', fontsize=font)\n",
    "        plt.title(ftitle, fontsize=font)\n",
    "    \n",
    "    #loop through files\n",
    "    for f in file_list:\n",
    "        #check if file and import if so\n",
    "        if os.path.isfile(f):\n",
    "            curve = extract_curve_number(f)\n",
    "            curves = np.append(curves, curve)\n",
    "            df = pd.read_csv(f)\n",
    "        \n",
    "            #plot desired plot type\n",
    "            if color=='':\n",
    "\n",
    "                if plot == 'd/t':\n",
    "                    ax1.plot(df['extension'], df['force average'], alpha=0.5)\n",
    "                    ax2.plot(df['time (seconds)'], df['force average'], alpha =0.5)\n",
    "                if plot == 'd/t/p':\n",
    "                    ax1.plot(df['extension'], df['force average'], alpha=0.5)\n",
    "                    ax2.plot(df['time (seconds)'], df['force average'], alpha =0.5)\n",
    "                    ax3.plot(df['time (seconds)'], df['trap_position 1x'], alpha=0.5)\n",
    "                elif plot == 'd':\n",
    "                    if smooth:\n",
    "                        plt.plot(df['extension'], df['force average'], alpha=0.5, color='gray')\n",
    "                        df['y_smoothed'] = df['force average'].rolling(window=smooth).mean()\n",
    "                        plt.plot(df['extension'], df['y_smoothed'], alpha=1, color='red')\n",
    "                    else:\n",
    "                        plt.plot(df['extension'], df['force average'], alpha=0.5)\n",
    "                elif plot == 't':\n",
    "                    if smooth:\n",
    "                        plt.plot(df['time (seconds)'], df['force average'], alpha=0.5, color='gray')\n",
    "                        df['y_smoothed'] = df['force average'].rolling(window=smooth).mean()\n",
    "                        plt.plot(df['time (seconds)'], df['y_smoothed'], alpha=1, color='red')\n",
    "                    else:\n",
    "                        plt.plot(df['time (seconds)'], df['force average'], alpha=0.5)\n",
    "            else:\n",
    "                if plot == 'd/t':\n",
    "                    ax1.plot(df['distance (um)'], df['force 2x (pN)'], alpha=0.5, color=color)\n",
    "                    ax2.plot(df['time (seconds)'], df['force 2x (pN)'], alpha =0.5, color=color)\n",
    "                elif plot == 'd':\n",
    "                    plt.plot(df['distance (um)'], df['force 2x (pN)'], alpha=0.5, color=color)\n",
    "                elif plot == 't':\n",
    "                    plt.plot(df['time (seconds)'], df['force 2x (pN)'], alpha=0.5, color=color)\n",
    "                \n",
    "    #add the legend\n",
    "    if legend == True:\n",
    "        plt.legend(curves)\n",
    "    elif legend != False:\n",
    "        plt.legend(legend)\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989c2b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_curve_number(filename):\n",
    "    # Regular expression pattern to match \"Curve\" followed by 1 to 3 digits\n",
    "    pattern = r\"Curve \\s*(\\d{1,3})\"\n",
    "    \n",
    "    # Search for the pattern in the filename\n",
    "    match = re.search(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the matched number\n",
    "        curve_number = match.group(1)\n",
    "        # Add preceding zero if it's a single digit number\n",
    "        if len(curve_number) == 1:\n",
    "            curve_number = '0' + curve_number\n",
    "        return curve_number\n",
    "    else:\n",
    "        return None  # Return None if no match is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec90ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cycle_number(filename):\n",
    "    # Regular expression pattern to match \"Curve\" followed by 1 to 3 digits\n",
    "    pattern = r\"Cycle \\s*(\\d{1,3})\"\n",
    "    \n",
    "    # Search for the pattern in the filename\n",
    "    match = re.search(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        # Extract the matched number\n",
    "        curve_number = match.group(1)\n",
    "        # Add preceding zero if it's a single digit number\n",
    "        if len(curve_number) == 1:\n",
    "            curve_number = '0' + curve_number\n",
    "        return curve_number\n",
    "    else:\n",
    "        return None  # Return None if no match is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be83331c-55db-4b52-a34d-84ac2bcb449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stiffness(date, curve, trap, directory, var = 'kappa', suffix = ''):\n",
    "    #find calibration files for particular date that are for the correct trap\n",
    "    f = []\n",
    "    cals = select_files(date, 'calibration', directory=directory)\n",
    "    for cal in cals:\n",
    "        if trap in cal:\n",
    "            f.append(cal)\n",
    "    \n",
    "    #if there are more than 1 (two condition day) require it have the correct \"suffix\"\n",
    "    if len(f) > 1:\n",
    "        f2 = []\n",
    "        for file in f:\n",
    "            if suffix in file:\n",
    "                f2.append(file)\n",
    "        f = f2\n",
    "\n",
    "    #open the calibration file\n",
    "    if os.path.isfile(f[0]) and len(f) == 1:\n",
    "        df = pd.read_csv(f[0])\n",
    "        if var == 'kappa':\n",
    "            return df.loc[df['curve'] == curve, 'kappa (pN/nm)'].values[0]\n",
    "        elif var == 'r':\n",
    "            return (df.loc[df['curve'] == curve, 'Bead diameter (um)'].values[0])/2\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e0d72-6233-4acd-afcf-d66e38496aa0",
   "metadata": {},
   "source": [
    "# 1) PC VERSION: Extract fitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddecd82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#PyLake versions and Mac vs PC seem to return different calibration objects\n",
    "\n",
    "#Fill in filepath, date, file selections and suffix (if desired to add to distinguish conditions from same date)\n",
    "\n",
    "#File path is assumed to lead to subfolders of dates in the format YY_MM_DD and end in /\n",
    "#Only selected files will be processed; an empty list ([]) will be treated as files being selected\n",
    "directory = \"\"\n",
    "date = ''\n",
    "selections = []\n",
    "suffix = ''\n",
    "\n",
    "folder = directory+date\n",
    "\n",
    "dates = date.split('_')\n",
    "YY = dates[0]\n",
    "MM = dates[1]\n",
    "DD = dates[2]\n",
    "\n",
    "#gather files\n",
    "file_list = select_files(date, 'h5', selections = selections, directory=directory)\n",
    "export = [\"1x\", '1y', '2x', '2y']\n",
    "\n",
    "i = 0\n",
    "for x in export:\n",
    "    df = pd.DataFrame()\n",
    "    name = date + suffix + '_' + x + '_calibration_stats.csv'\n",
    "    fname = os.path.join(folder, name)\n",
    "    for f in file_list:\n",
    "        file = lk.File(f)\n",
    "        if x == '1x':\n",
    "            data = file.force1x.calibration[0]\n",
    "        elif x == '2x':\n",
    "            data = file.force2x.calibration[0]\n",
    "        elif x == '1y':\n",
    "            data = file.force1y.calibration[0]\n",
    "        elif x == '2y':\n",
    "            data = file.force2y.calibration[0]\n",
    "        curve = extract_curve_number(f)\n",
    "        data['date'] = date\n",
    "        data['curve'] = int(curve)\n",
    "        data['fname'] = DD + MM + YY + 'N' + curve + \".csv\"\n",
    "        row_df = pd.DataFrame(data, index=[i])\n",
    "        df = pd.concat([df, row_df], ignore_index=True)\n",
    "        i += 1\n",
    "        del file\n",
    "        gc.collect()\n",
    "    \n",
    "    curve_col = df.pop(\"curve\")\n",
    "    df.insert(0, \"curve\", curve_col)\n",
    "    fname_col = df.pop(\"fname\")\n",
    "    df.insert(0, \"fname\", fname_col)\n",
    "    date_col = df.pop(\"date\")\n",
    "    df.insert(0, \"date\", date_col)\n",
    "    df.to_csv(fname)\n",
    "    print(x + ' done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e39023-7503-427c-ac50-ac686d54964d",
   "metadata": {},
   "source": [
    "# 1) MAC VERSION: Extract fitting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff38d74-89fc-482b-ac5d-65a5ecd1441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyLake versions and Mac vs PC seem to return different calibration objects\n",
    "\n",
    "#Fill in filepath, date, file selections and suffix (if desired to add to distinguish conditions from same date)\n",
    "\n",
    "#File path is assumed to lead to subfolders of dates in the format YY_MM_DD and end in /\n",
    "#Only selected files will be processed; an empty list ([]) will be treated as files being selected\n",
    "directory = \"\"\n",
    "date = ''\n",
    "selections = []\n",
    "suffix = ''\n",
    "\n",
    "folder = os.path.join(directory, date)\n",
    "\n",
    "YY, MM, DD = date.split('_')\n",
    "\n",
    "# === Gather files ===\n",
    "file_list = select_files(date, 'h5', selections=selections, directory=directory)\n",
    "export = [\"1x\", \"1y\", \"2x\", \"2y\"]\n",
    "\n",
    "# === Process each force channel ===\n",
    "for x in export:\n",
    "    all_rows = []\n",
    "\n",
    "    for f in file_list:\n",
    "        file = lk.File(f)\n",
    "\n",
    "        # Select calibration object\n",
    "        if x == '1x':\n",
    "            data = file.force1x.calibration[0]\n",
    "        elif x == '1y':\n",
    "            data = file.force1y.calibration[0]\n",
    "        elif x == '2x':\n",
    "            data = file.force2x.calibration[0]\n",
    "        elif x == '2y':\n",
    "            data = file.force2y.calibration[0]\n",
    "\n",
    "        # Extract all public attributes (avoid methods and private)\n",
    "        data_dict = {\n",
    "            k: getattr(data, k)\n",
    "            for k in dir(data)\n",
    "            if not k.startswith(\"_\") and not callable(getattr(data, k))\n",
    "        }\n",
    "\n",
    "        # Convert to wide DataFrame (one row)\n",
    "        df_wide = pd.DataFrame([data_dict])\n",
    "        # Each row's dict becomes columns; keeps any other columns you already had\n",
    "        df_wide = pd.json_normalize(df_wide.pop(\"data\"))\n",
    "\n",
    "\n",
    "        # Add metadata columns\n",
    "        curve = extract_curve_number(f)\n",
    "        df_wide[\"curve\"] = int(curve)\n",
    "        df_wide[\"fname\"] = DD + MM + YY + \"N\" + curve + \".csv\"\n",
    "        df_wide[\"date\"] = date\n",
    "\n",
    "        # Move identifying columns to the front\n",
    "        df_wide = df_wide[[\"date\", \"fname\", \"curve\"] + [c for c in df_wide.columns if c not in [\"date\", \"fname\", \"curve\"]]]\n",
    "\n",
    "        all_rows.append(df_wide)\n",
    "\n",
    "        del file\n",
    "        gc.collect()\n",
    "\n",
    "    # Combine all rows for this channel\n",
    "    df_final = pd.concat(all_rows, ignore_index=True)\n",
    "\n",
    "    # Save output CSV\n",
    "    name = f\"{date}{suffix}_{x}_calibration_stats.csv\"\n",
    "    fname = os.path.join(folder, name)\n",
    "    df_final.to_csv(fname, index=True)\n",
    "\n",
    "    print(f\"{x} done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a1268",
   "metadata": {},
   "source": [
    "# 2) Downsample and convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231838b-837d-415f-9816-8dedd7101b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in filepath, date, file selections, and desired compression\n",
    "\n",
    "#File path is assumed to lead to subfolders of dates in the format YY_MM_DD and end in /\n",
    "#Only selected files will be processed; an empty list ([]) will be treated as files being selected\n",
    "#select desired compression in Hz to down sample to\n",
    "#\"1\" is treated as no down sampling\n",
    "#we used 2500 hz for unzipping analysis and 2000 hz for dynamic analysis\n",
    "directory=\"\"\n",
    "date = ''\n",
    "selections = []\n",
    "compress = 2500 \n",
    "\n",
    "folder = directory+date\n",
    "\n",
    "#Set constant\n",
    "suffix = '.csv'\n",
    "if compress != 1:\n",
    "    sampling = ' down sampled to ' + str(compress) + ' Hz'\n",
    "else:\n",
    "    sampling = ' down sampled to ' + str(compress) + 'x'\n",
    "\n",
    "#gather list of files\n",
    "file_list = select_files(date, 'h5', selections=selections, directory=directory)\n",
    "\n",
    "i=1\n",
    "\n",
    "#loop through h5s and extract downsampled info\n",
    "for filename in file_list:\n",
    "    \n",
    "    #downsample info and save to a dataframe\n",
    "    if compress != 1:\n",
    "        mt, mf1x, mf1y, mp1x, mf2x, mf2y, mp1y, p2x, p2y = h5_extract(filename, compress)\n",
    "    else:\n",
    "        mt, mf1x, mf1y, mp1x, mf2x, mf2y, mp1y, p2x, p2y = h5_extract(filename)\n",
    "\n",
    "    #handles issues in some versions of Lumicks software where position data from trap 2 is exported weirdly\n",
    "    if mt.size == 0:\n",
    "        continue\n",
    "    mp2x = [p2x[0]] * len(mp1x)\n",
    "    mp2y = [p2y[0]] * len(mp1x)\n",
    "    \n",
    "    data = {'time (seconds)' : mt,\n",
    "       'force 1x (pN)' : mf1x,\n",
    "        'force 1y (pN)' : mf1y,\n",
    "        'trap_position 1x': mp1x,\n",
    "        'force 2x (pN)' : mf2x,\n",
    "        'force 2y (pN)' : mf2y,\n",
    "        'trap_position 1y': mp1y,\n",
    "        'trap_position 2x': mp2x,\n",
    "        'trap_position 2y': mp2y,}\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    \n",
    "    #make new file name\n",
    "    curve = extract_curve_number(filename)\n",
    "    new_name = date + ' FD Curve ' + curve + sampling + suffix\n",
    "    new_file_name = os.path.join(folder, new_name)\n",
    "    \n",
    "    #save to csv\n",
    "    df.to_csv(new_file_name)\n",
    "\n",
    "    del filename\n",
    "    gc.collect()\n",
    "\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c214a",
   "metadata": {},
   "source": [
    "# 3) Subtract baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31509369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If present, subtract the force baseline from the data\n",
    "#This is done by fitting the baseline file to a 7th order polynomial (at Lumick's recomendation), and subtracting\n",
    "#the resulting function from the data. \n",
    "#Whether or not a baseline file exists, the first 200-400 points of the data are fit to a line with slope 0 and used to shift\n",
    "#the data to start at 0.1 pN to \"zero\" the force.\n",
    "\n",
    "#Fill in filepath, date, file selections, and whether files are from dynamic traces\n",
    "\n",
    "#File path is assumed to lead to subfolders of dates in the format YY_MM_DD and end in /\n",
    "#Only selected files will be processed; an empty list ([]) will be treated as files being selected\n",
    "#Set dynamic = False for unzipping and True for dynamic traces containing validation unzipping; changes which segment is used for correction\n",
    "\n",
    "###Assumes there is a subfolder titled \"baseline\" containing downsampled baseline curves and \n",
    "#a CSV titled \"baselines.csv\" with a column for each baseline\n",
    "#with the first row being curve numbers of baselines and below each baseline, listing the curve numbers of files to map to that baseline\n",
    "#e.g. 1 4 8     \n",
    "#     2 7 9\n",
    "#     3\n",
    "#maps curves 2 and 3 to baseline curve 1, 7 to baseline 4, and 9 to baseline 8\n",
    "\n",
    "directory=\"\"\n",
    "date = ''\n",
    "selections = []\n",
    "dynamic = False\n",
    "\n",
    "folder = directory+date\n",
    "\n",
    "#gather files\n",
    "file_list = select_files(date, 'down', selections = selections, directory=directory)\n",
    "\n",
    "# Loop through files\n",
    "for f in file_list:\n",
    "    \n",
    "    #import data and create new column\n",
    "    df = pd.read_csv(f)\n",
    "    df['force baseline 1x'] = df['force 1x (pN)']\n",
    "    df['force baseline 2x'] = df['force 2x (pN)']\n",
    "    curve = extract_curve_number(f)\n",
    "    \n",
    "    #find baseline if present; can set to -1 to skip\n",
    "    curve_base = (has_baseline(folder, curve))\n",
    "    \n",
    "    #if present, remove baseline\n",
    "    if curve_base != -1:\n",
    "\n",
    "        # Extract baseline and fit a 7th-order polynomial (based on Lumicks recomendation) to each force (1x, 1y, 2x, 2y)\n",
    "        file_list2 = select_files((date+'/baseline/'), 'down', selections = [curve_base], directory=directory)\n",
    "        base = pd.read_csv(file_list2[0])\n",
    "        x = base[base['trap_position 1x'] > 2.3]['trap_position 1x']\n",
    "        y1x = base[base['trap_position 1x'] > 2.3]['force 1x (pN)']\n",
    "        y2x = base[base['trap_position 1x'] > 2.3]['force 2x (pN)']\n",
    "        x_data = df['trap_position 1x']\n",
    "        \n",
    "        coeffs1x = np.polyfit(x, y1x, 7)\n",
    "        coeffs2x = np.polyfit(x, y2x, 7)\n",
    "        \n",
    "        # Create a polynomial function from the coefficients for each force\n",
    "        poly1x = np.poly1d(coeffs1x)\n",
    "        poly2x = np.poly1d(coeffs2x)\n",
    "\n",
    "        #UNCOMMENT BLOCK TO PLOT CORRECTED BASELINE AS TEST\n",
    "        # fix_1x = y1x - poly1x(x)\n",
    "        # #fix_1y = y1y - poly1y(x)\n",
    "        # fix_2x = y2x - poly2x(x)\n",
    "        # #fix_2y = y2y - poly2y(x)\n",
    "        \n",
    "        # fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "        # ax[0].plot(x, y1x)\n",
    "        # ax[0].plot(x, fix_1x)\n",
    "        # ax[0].plot(x, poly1x(x))\n",
    "        # ax[0].set_title('baseline force 1x')\n",
    "        # ax[0].legend(['raw', 'corrected', 'fit'])\n",
    "        # ax[0].set_xlabel('trap position (um)')\n",
    "        # ax[0].set_ylabel('force (pN)')\n",
    "        # # ax[0, 1].plot(x, y1y)\n",
    "        # # ax[0, 1].plot(x, fix_1y)\n",
    "        # # ax[0, 1].set_title('1y')\n",
    "        # ax[1].plot(x, y2x)\n",
    "        # ax[1].plot(x, fix_2x)\n",
    "        # ax[1].plot(x, poly2x(x))\n",
    "        # ax[1].set_title('baseline force 2x')\n",
    "        # ax[1].set_xlabel('trap position (um)')\n",
    "        # ax[1].set_ylabel('force (pN)')\n",
    "        # # ax[1, 1].plot(x, y2y)\n",
    "        # # ax[1, 1].plot(x, fix_2y)\n",
    "        # # ax[1, 1].set_title('2y')\n",
    "        # plt.tight_layout()\n",
    "\n",
    "        #baseline correct data\n",
    "        df['force baseline 1x'] = df['force 1x (pN)'] - poly1x(df['trap_position 1x'])\n",
    "        df['force baseline 2x'] = df['force 2x (pN)'] - poly2x(df['trap_position 1x'])\n",
    "    else:\n",
    "        print('no baseline')\n",
    "\n",
    "    #fit first 400 points to a line with slope 0 to \"zero\" to 0.1 pN; can change number of points if desired\n",
    "    points=399\n",
    "    m = 0\n",
    "    new_min = 0.1\n",
    "    def line(x, b):\n",
    "        return m * x + b  # Only fit m\n",
    "\n",
    "    if not dynamic:\n",
    "        params, _ = curve_fit(line, df['trap_position 1x'][0:points], df['force baseline 1x'][0:points])\n",
    "        b1x = params[0]\n",
    "        params, _ = curve_fit(line, df['trap_position 1x'][0:points], df['force baseline 2x'][0:points])\n",
    "        b2x = params[0]\n",
    "    else:\n",
    "        curve = extract_curve_number(f)\n",
    "        valleysx, valleysy, num_peaks, peak_dict = find_peaks(df, date, curve, cycle=-1, var = 'trap', peak_dict=None,\n",
    "                                                             sign = '-', num_peaks = -1, interval = 1000)\n",
    "        start=valleysx[-1]\n",
    "        params, _ = curve_fit(line, df['trap_position 1x'][start:start+points], df['force baseline 1x'][start:start+points])\n",
    "        b1x = params[0]\n",
    "        params, _ = curve_fit(line, df['trap_position 1x'][start:start+points], df['force baseline 2x'][start:start+points])\n",
    "        b2x = params[0]\n",
    "\n",
    "    df['force baseline 1x'] = df['force baseline 1x'] - b1x + new_min\n",
    "    df['force baseline 2x'] = df['force baseline 2x'] - b2x + new_min\n",
    "\n",
    "    #UNCOMMENT BLOCK TO PLOT CORRECTED DATA AS TEST\n",
    "    # fig, ax = plt.subplots(2, 1, figsize=(8, 6))\n",
    "    # ax[0].plot(df['trap_position 1x'], df['force 1x (pN)'].rolling(window=10).mean())\n",
    "    # ax[0].plot(df['trap_position 1x'], df['force baseline 1x'].rolling(window=10).mean())\n",
    "    # ax[0].set_title('Unzipping force 1x (steered trap)')\n",
    "    # ax[0].set_xlabel('trap position (um)')\n",
    "    # ax[0].set_ylabel('force (pN)')\n",
    "    # ax[0].legend(['raw', 'corrected'])\n",
    "    # # ax[0, 1].plot(df['trap_position 1x'], df['force 1y (pN)'].rolling(window=10).mean())\n",
    "    # # ax[0, 1].set_title('1y')\n",
    "    # ax[1].plot(df['trap_position 1x'], df['force 2x (pN)'].rolling(window=10).mean())\n",
    "    # ax[1].plot(df['trap_position 1x'], df['force baseline 2x'].rolling(window=10).mean())\n",
    "    # ax[1].set_title('Unzipping force 2x (stationary trap)')\n",
    "    # ax[1].set_xlabel('trap position (um)')\n",
    "    # ax[1].set_ylabel('force (pN)')\n",
    "    # # ax[1, 1].plot(df['trap_position 1x'], df['force 2y (pN)'].rolling(window=10).mean())\n",
    "    # # ax[1, 1].set_title('2y')\n",
    "    \n",
    "    # # ax[0].plot(df['trap_position 1x'], df['force baseline 1y'].rolling(window=10).mean())\n",
    "    # # ax[1].plot(df['trap_position 1x'], df['force baseline 2y'].rolling(window=10).mean())\n",
    "    # plt.tight_layout()\n",
    "    # #plt.close('all')\n",
    "\n",
    "    #save file\n",
    "    df.to_csv(f)\n",
    "    print('curve ' + curve + ' done')\n",
    "\n",
    "    del f\n",
    "    gc.collect()\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1753fa-87f0-488b-b212-fdd43906fa67",
   "metadata": {},
   "source": [
    "# 4) Calculate extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56fbe43-fa2d-4e1e-9a92-e15d1a9a7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn trap position into extension utilizing the trap stiffnesses and baseline-corrected forces\n",
    "\n",
    "#Fill in filepath, date, file selections and suffix (if desired to add to distinguish conditions from same date)\n",
    "\n",
    "#File path is assumed to lead to subfolders of dates in the format YY_MM_DD and end in /\n",
    "#Only selected files will be processed; an empty list ([]) will be treated as files being selected\n",
    "directory = \"\"\n",
    "date = ''\n",
    "selections = []\n",
    "suffix = ''\n",
    "\n",
    "#gather files\n",
    "file_list = select_files(date, 'down', selections = selections, directory=directory)\n",
    "\n",
    "# Loop through files\n",
    "for f in file_list:\n",
    "    df = pd.read_csv(f)\n",
    "\n",
    "    #extract parameters from calibration\n",
    "    curve = int(extract_curve_number(f))\n",
    "    k1x = extract_stiffness(date, curve, '1x', directory=directory, var='kappa', suffix=suffix)*1000\n",
    "    k2x = extract_stiffness(date, curve, '2x', directory=directory, var='kappa', suffix=suffix)*1000\n",
    "\n",
    "    #correct for bead displacement with stiffnesses and forces\n",
    "    df['extension'] = df['trap_position 1x'] - (df['force baseline 1x']/k1x) - (df['force baseline 2x']/k2x) #- r1 - r2\n",
    "    df['force average'] = (df['force baseline 1x'] + df['force baseline 2x'])/2\n",
    "\n",
    "    df.to_csv(f)\n",
    "    print('curve ' + str(curve) + ' done')\n",
    "\n",
    "    #UNCOMMENT BLOCK TO PLOT CORRECTED DATA AS TEST\n",
    "    # #plt.plot(df['extension'], df['force baseline 1x'])\n",
    "    # plt.plot(df['trap_position 1x'], df['force baseline 2x'])\n",
    "    # plt.plot(df['extension'], df['force baseline 2x'])\n",
    "    # plt.xlabel('microns')\n",
    "    # plt.ylabel('Force (pN)')\n",
    "    # #plt.plot(df['extension'], df['force average'])\n",
    "    # plt.legend(['Force 2x vs trap position 1', 'Force 2x vs DNA extension'])\n",
    "    # #plt.close('all')\n",
    "\n",
    "    del f\n",
    "    gc.collect()\n",
    "    \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff09d7c",
   "metadata": {},
   "source": [
    "## Optional: Rename files for Matlab pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e61c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downstream MATLAB pipeline expects a different file naming scheme as input\n",
    "#This function copies data into a new file with appropriate naming\n",
    "#DDMMYYNXX (e.g \"24_04_10 FD Curve 73 down sampled to 2500 Hz.csv\" to be 100424N73)\n",
    "\n",
    "#Fill in filepath, date, and file selections\n",
    "\n",
    "#File path is assumed to lead to subfolders of dates in the format YY_MM_DD and end in /\n",
    "#Only selected files will be processed; an empty list ([]) will be treated as files being selected\n",
    "#Change to cycles = True if converting files that were split into cycles; file will be saved as DDMMYYNXXCC (where CC is cycle number)\n",
    "directory=\"\"\n",
    "date = ''\n",
    "selections = []\n",
    "cycles = False\n",
    "\n",
    "suffix = \".csv\"\n",
    "folder = directory+ date\n",
    "\n",
    "#gather files\n",
    "file_list = select_files('', 'down', selections = selections, cycles=cycles, directory=folder)\n",
    "\n",
    "#If saving cycles, only keeps F cycles (forward) by default\n",
    "fi2 = []\n",
    "for i in range(0, len(file_list)):\n",
    "    if \"R down\" not in file_list[i]:\n",
    "            fi2.append(file_list[i])\n",
    "\n",
    "dates = date.split('_')\n",
    "YY = dates[0]\n",
    "MM = dates[1]\n",
    "DD = dates[2]\n",
    "\n",
    "#Loop through files and get curve and cycle\n",
    "for f in fi2:\n",
    "    curve = extract_curve_number(f)\n",
    "    if cycles:\n",
    "        cycle = extract_cycle_number(f)\n",
    "    else:\n",
    "        cycle = \"\"\n",
    "\n",
    "    df = pd.read_csv(f)\n",
    "    new_name = DD + MM + YY + 'N' + curve + cycle + suffix\n",
    "    # new_name = DD + MM + YY + 'N' + curve + suffix\n",
    "    new_file_name = os.path.join(folder, new_name)\n",
    "    \n",
    "    #save to csv\n",
    "    df.to_csv(new_file_name)\n",
    "    \n",
    "    print(DD + MM + YY + 'N' + curve + cycle + \" Done!\")\n",
    "    #print(DD + MM + YY + 'N' + curve + \" Done!\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f8cbf",
   "metadata": {},
   "source": [
    "# Optional: Plot curves for figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157b4b67-a71d-4d31-9a33-31507cf9cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File in filepath, date, file selections, whether the data is full unzipping or cycles, the type of desired plot,\n",
    "#whether a legend and title are desired, and if you want data smoothed\n",
    "\n",
    "#File path is assumed to lead to subfolders of dates in the format YY_MM_DD and end in /\n",
    "#Only selected files will be processed; an empty list ([]) will be treated as files being selected\n",
    "#Change to cycles = True if plotting files that were split into cycles\n",
    "#Plot can be set to \"d\" (force vs extension), \"t\" (force vs time), \"d/t\" (side by side subplots of \"d\" and \"t\"), \n",
    "#or \"d/t/p\" (side by side subplots of \"d\", \"t\", and extension vs time)\n",
    "#legend can be set to True (curve numbers), False (none), or a list of condition names\n",
    "#ftitle species a figure title\n",
    "#smooth can be false or an integer specifying degree of smoothness (currently only works for \"d\" and \"t\" not \"d/t\" or \"d/t/p\")\n",
    "directory=\"\"\n",
    "date = ''\n",
    "selections = []\n",
    "cycles = False\n",
    "plot = 'd'\n",
    "legend = True\n",
    "ftitle = ''\n",
    "smooth = False\n",
    "\n",
    "fi = select_files(date, 'down', directory, selections, cycles=cycles)\n",
    "\n",
    "fi2 = []\n",
    "for i in range(0, len(fi)):\n",
    "    if \"R down\" not in fi[i]:\n",
    "            fi2.append(fi[i])\n",
    "\n",
    "fig = plot_curves(fi2, plot=plot, legend=legend, ftitle=ftitle, smooth=smooth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d86900",
   "metadata": {},
   "source": [
    "# Optional: Split into cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5600d301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill in filepath, date, and file selections\n",
    "\n",
    "#File path is assumed to lead to subfolders of dates in the format YY_MM_DD and end in /\n",
    "#Assumes there is a subfolder titled \"cycles\"\n",
    "#Only selected files will be processed; an empty list ([]) will be treated as files being selected\n",
    "directory = \"\"\n",
    "date = ''\n",
    "selections = []\n",
    "\n",
    "folder = directory+date + '/cycles/'\n",
    "\n",
    "#gather files\n",
    "file_list = select_files(date, 'down', selections = selections, directory=directory)\n",
    "\n",
    "#Loop through files\n",
    "for f in file_list:\n",
    "    \n",
    "    #import data\n",
    "    df = pd.read_csv(f)\n",
    "    curve = extract_curve_number(f)\n",
    "    \n",
    "    cycle = str(-1)\n",
    "    \n",
    "    #find position peaks and valleys\n",
    "    peak_dict = None\n",
    "    peaksx, peaksy, num_peaks, peak_dict = find_peaks(df, date, curve, cycle, var = 'trap', peak_dict=peak_dict,\n",
    "                                                      sign = '+', num_peaks = -1, interval = 1000)\n",
    "    valleysx, valleysy, num_peaks, peak_dict = find_peaks(df, date, curve, cycle, var = 'trap', peak_dict=peak_dict,\n",
    "                                                          sign = '-', num_peaks = num_peaks, interval = 1000)\n",
    "    \n",
    "    if len(peaksx) == 0:\n",
    "        continue\n",
    "    \n",
    "    #loop through cycles\n",
    "    for i in range(0, len(peaksx)):\n",
    "        \n",
    "        #make new file names\n",
    "        stri = str(i+1)\n",
    "        if i+1 <10:\n",
    "            stri = '0' + stri\n",
    "        \n",
    "        curve = extract_curve_number(f)\n",
    "        \n",
    "        suffix = '.csv'\n",
    "        loc1 = f.find('down')\n",
    "        loc2 = f.find('x.csv')\n",
    "        new_name = date + ' FD Curve ' + curve + ' Cycle ' + stri \n",
    "        new_nameF = new_name + \" F\" + ' down sampled to 2500 Hz' + suffix\n",
    "        new_nameR = new_name + \" R\" + ' down sampled to 2500 Hz' + suffix\n",
    "        \n",
    "        new_file_nameF = os.path.join(folder, new_nameF)\n",
    "        new_file_nameR = os.path.join(folder, new_nameR)\n",
    "        \n",
    "        #split cycles and save F to csv\n",
    "        df_f = df.iloc[valleysx[i]:peaksx[i], :]\n",
    "        df_f.to_csv(new_file_nameF)\n",
    "        \n",
    "        #split cycles and save R to csv\n",
    "        if not (len(peaksx) == len(valleysx) and i == len(peaksx)-1):\n",
    "            df_r = df.iloc[peaksx[i]:valleysx[i+1], :]\n",
    "            df_r.to_csv(new_file_nameR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
